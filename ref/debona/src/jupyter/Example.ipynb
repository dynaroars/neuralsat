{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gurobipy as grb\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.neural_networks.verinet_nn import VeriNetNN\n",
    "from src.algorithm.verinet import VeriNet\n",
    "from src.data_loader.input_data_loader import load_neurify_mnist, load_cifar10_human_readable\n",
    "from src.data_loader.nnet import NNET\n",
    "from src.algorithm.verification_objectives import LocalRobustnessObjective\n",
    "from src.algorithm.verinet_util import Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 50 images and create bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "images = load_neurify_mnist(\"../../data/mnist_neurify/test_images_100/\", list(range(100))).reshape(-1, 784)\n",
    "print(images.shape)\n",
    "eps = 5\n",
    "input_bounds = np.zeros((*images.shape, 2), dtype=np.float32)\n",
    "input_bounds[:, :, 0] = images - eps\n",
    "input_bounds[:, :, 1] = images + eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network, normalise data, and initialise solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NNET(\"../../data/models_nnet/neurify/mnist24.nnet\")\n",
    "images = nnet.normalize_input(images)\n",
    "input_bounds = nnet.normalize_input(input_bounds)\n",
    "\n",
    "model = nnet.from_nnet_to_verinet_nn()\n",
    "model.eval()\n",
    "solver = VeriNet(model, max_procs=20)\n",
    "targets = model(torch.Tensor(images)).argmax(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifiy inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image   0: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image   1: Status.Safe  , branches explored:  21, max depth:  6\n",
      "Image   2: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image   3: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image   4: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image   5: Status.Safe  , branches explored:  17, max depth:  4\n",
      "Image   6: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image   7: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image   8: Status.Safe  , branches explored: 341, max depth: 15\n",
      "Image   9: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  10: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  11: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  12: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  13: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  14: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  15: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  16: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  17: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  18: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  19: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  20: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  21: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  22: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  23: Status.Safe  , branches explored:   7, max depth:  3\n",
      "Image  24: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  25: Status.Safe  , branches explored:  81, max depth:  8\n",
      "Image  26: Status.Safe  , branches explored:   3, max depth:  1\n",
      "Image  27: Status.Safe  , branches explored: 325, max depth: 17\n",
      "Image  28: Status.Safe  , branches explored:   3, max depth:  1\n",
      "Image  29: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  30: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  31: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  32: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  33: Status.Unsafe, branches explored:   1, max depth:  0\n",
      "Image  34: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  35: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  36: Status.Safe  , branches explored:   1, max depth:  0\n",
      "Image  37: Status.Safe  , branches explored:   1, max depth:  0\n"
     ]
    }
   ],
   "source": [
    "counter_examples = []\n",
    "counter_examples_idx = []\n",
    "\n",
    "for i, input_bound in enumerate(input_bounds):\n",
    "    objective = LocalRobustnessObjective(targets[i], input_bound, output_size=10)\n",
    "    status = solver.verify(objective, timeout=3600, no_split=False, verbose=False)\n",
    "    \n",
    "    if status == Status.Unsafe:\n",
    "        counter_examples.append(solver.counter_example)\n",
    "        counter_examples_idx.append(i)\n",
    "        \n",
    "    print(f\"Image {i:3}: {status:13}, branches explored: {solver.branches_explored:3}, max depth: {solver.max_depth:2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise counterexamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(len(counter_examples_idx)):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    counter_example = counter_examples[idx]\n",
    "    image = images[counter_examples_idx[idx]]\n",
    "    \n",
    "    diff = (abs(counter_example - image) * 255).astype(np.int32) * 10\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(image.reshape((28,28)), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Class={model(torch.Tensor(image)).argmax(dim=1).numpy()[0]}\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(diff.reshape((28, 28)), cmap=\"gray\", vmin=0, vmax=255)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Noise x10\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(counter_example.reshape(28, 28), cmap=\"gray\")\n",
    "    plt.axis('off');\n",
    "    plt.title(f\"Predicted={model(torch.Tensor(counter_example)).argmax(dim=1).numpy()[0]}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verinet",
   "language": "python",
   "name": "verinet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
